{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0dd1202",
   "metadata": {},
   "source": [
    "# Proof of concept notebook for the Frame Booster project\n",
    "- Author: Kamil Barszczak\n",
    "- Contact: kamilbarszczak62@gmail.com\n",
    "- Project: https://github.com/kbarszczak/Frame_booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c6c603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamil\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from keras import preprocessing\n",
    "from keras import regularizers\n",
    "from keras import activations\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import models\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666c9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "model_base_path = 'E:/OneDrive - Akademia Górniczo-Hutnicza im. Stanisława Staszica w Krakowie/Programming/Labs/Frame_booster/models/model_v3'\n",
    "model_name = 'frame_booster'\n",
    "width, height = 256, 144\n",
    "\n",
    "# training data parameters\n",
    "data_base_path = 'E:/Data/Video_Frame_Interpolation/processed/vimeo90k'\n",
    "data_creation_time ='1682372054'\n",
    "data_train_size = '19000'\n",
    "data_test_size = '1000'\n",
    "data_valid_size = '1000'\n",
    "batch_size = 5\n",
    "epochs = 10\n",
    "\n",
    "# visualization data parameters\n",
    "vis_base_path = 'E:/Data/Video_Frame_Interpolation/processed/low_motion'\n",
    "vis_creation_time = '1682179015'\n",
    "vis_prefix = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6906d",
   "metadata": {},
   "source": [
    "## Load generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4547c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_features = {\n",
    "    'image_1': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_2': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_3': tf.io.FixedLenFeature([], tf.string),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48201b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_decode_record(record):\n",
    "    features = tf.io.parse_single_example(record, name_to_features)\n",
    "    image_1 = tf.io.decode_raw(\n",
    "        features['image_1'], out_type='float32', little_endian=True, fixed_length=None, name=None\n",
    "    )\n",
    "    image_1 = tf.reshape(image_1, (height, width, 3))\n",
    "    \n",
    "    image_2 = tf.io.decode_raw(\n",
    "        features['image_2'], out_type='float32', little_endian=True, fixed_length=None, name=None\n",
    "    )\n",
    "    image_2 = tf.reshape(image_2, (height, width, 3))\n",
    "    \n",
    "    image_3 = tf.io.decode_raw(\n",
    "        features['image_3'], out_type='float32', little_endian=True, fixed_length=None, name=None\n",
    "    )\n",
    "    image_3 = tf.reshape(image_3, (height, width, 3))\n",
    "    \n",
    "    return (image_1, image_3), image_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb1352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generator(base_path, prefix, creation_time, width, height, size):\n",
    "    path = os.path.join(base_path, f'{prefix}_{size}_{height}x{width}_{creation_time}.tfrecords')\n",
    "    generator = tf.data.TFRecordDataset(path)\n",
    "\n",
    "    generator = generator.map(parse_decode_record)\n",
    "    generator = generator.repeat(epochs)\n",
    "    generator = generator.prefetch(5)\n",
    "    generator = generator.shuffle(buffer_size=5 * batch_size)\n",
    "    generator = generator.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f53bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = load_generator(\n",
    "    base_path = data_base_path, \n",
    "    prefix = 'train',\n",
    "    creation_time = data_creation_time, \n",
    "    width = width, \n",
    "    height = height, \n",
    "    size = data_train_size\n",
    ")\n",
    "test_generator = load_generator(\n",
    "    base_path = data_base_path, \n",
    "    prefix = 'test',\n",
    "    creation_time = data_creation_time, \n",
    "    width = width, \n",
    "    height = height, \n",
    "    size = data_test_size\n",
    ")\n",
    "valid_generator = load_generator(\n",
    "    base_path = data_base_path, \n",
    "    prefix = 'valid',\n",
    "    creation_time = data_creation_time, \n",
    "    width = width, \n",
    "    height = height, \n",
    "    size = data_valid_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432aaeb",
   "metadata": {},
   "source": [
    "## Load data for test visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a99e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path, prefix, creation_time, width, height):\n",
    "    with open(os.path.join(base_path, f'x_{prefix}_{height}x{width}_{creation_time}.pickle'), 'rb') as file:\n",
    "        x = pickle.load(file)\n",
    "        \n",
    "    with open(os.path.join(base_path, f'y_{prefix}_{height}x{width}_{creation_time}.pickle'), 'rb') as file:\n",
    "        y = pickle.load(file)\n",
    "        \n",
    "    return (np.array(x)/255.0).astype('float32'), (np.array(y)/255.0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b4700c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vis, y_vis = load_data(\n",
    "    base_path = vis_base_path,\n",
    "    prefix = vis_prefix,\n",
    "    creation_time = vis_creation_time,\n",
    "    width = width, \n",
    "    height = height\n",
    ")\n",
    "if len(x_vis) % batch_size != 0:\n",
    "    x_vis = x_vis[0:len(x_vis) - (len(x_vis)%batch_size)]\n",
    "    y_vis = y_vis[0:len(x_vis)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92349fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_generator = ImageDataGenerator().flow(\n",
    "    x = [x_vis[:, 0, :, :], x_vis[:, 1, :, :]],\n",
    "    y = y_vis,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1bbc7d",
   "metadata": {},
   "source": [
    "## Create loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae69db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The L1 reconstruction loss function makes the final image colors \n",
    "look the same as the colors in the ground-truth image\n",
    "\"\"\"\n",
    "def l1(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The L2 reconstruction loss function is similar to L1\n",
    "\"\"\"\n",
    "def l2(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The PSNR loss function is responsible for boosting the overall quality of the image by reducing its noise \n",
    "(The higher the PSNR the better so we return 1 - PSNR because the loss function tries to minimize it)\n",
    "\"\"\"\n",
    "def psnr(y_true, y_pred):\n",
    "    psnr = tf.image.psnr(y_true, y_pred, max_val = 1.0)\n",
    "    return 1 - psnr / 40.0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The SSIM loss function keeps the result image structure\n",
    "(The more significant the SSIM the more similar the final image is)\n",
    "\"\"\"\n",
    "def ssim(y_true, y_pred):\n",
    "    ssim = tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "    return 1 - ssim\n",
    "\n",
    "def output_activation(x):\n",
    "    return tf.math.minimum(tf.math.maximum(x, 0), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444234c",
   "metadata": {},
   "source": [
    "## Create custom layers for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07eb6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BidirectionalFlowEstimation is a layer that warps the features extracted at the given level trying \n",
    "to modify them to fit the target image. It predicts the flow between features of both the input_1 \n",
    "and the input_2 and warps them to get the final output. The output shape is the same as the input shape.\n",
    "\"\"\"\n",
    "class BidirectionalFlowEstimation(layers.Layer):\n",
    "    def __init__(self, filter_count=[32, 64, 64, 16], filter_size=[(3, 3), (3, 3), (1, 1), (1, 1)], activation='relu', regularizer=None, interpolation='bilinear', **kwargs):\n",
    "        super(BidirectionalFlowEstimation, self).__init__(**kwargs)\n",
    "        \n",
    "        # flow 1 -> 2\n",
    "        self.flow_add_1_2 = layers.Add()\n",
    "        self.flow_upsample_1_2 = layers.UpSampling2D((2, 2), interpolation=interpolation)\n",
    "        self.flow_1_2_concat = layers.Concatenate(axis=3)\n",
    "        self.flow_prediction_1_2 =  keras.Sequential([\n",
    "            layers.Conv2D(filter_count[0], filter_size[0], activation=activation, kernel_regularizer=regularizer, padding='same'),\n",
    "            layers.Conv2D(filter_count[1], filter_size[1], activation=activation, kernel_regularizer=regularizer, padding='same'),\n",
    "            layers.Conv2D(filter_count[2], filter_size[2], activation=activation, kernel_regularizer=regularizer, padding='same'),\n",
    "            layers.Conv2D(filter_count[3], filter_size[3], activation=activation, kernel_regularizer=regularizer, padding='same'),\n",
    "            layers.Conv2D(2, (1, 1), kernel_regularizer=regularizer, padding='same')\n",
    "        ])\n",
    "        \n",
    "        # flow 2 -> 1\n",
    "        self.flow_add_2_1 = layers.Add()\n",
    "        self.flow_upsample_2_1 = layers.UpSampling2D((2, 2), interpolation=interpolation)\n",
    "        self.flow_2_1_concat = layers.Concatenate(axis=3)\n",
    "        self.flow_prediction_2_1 = keras.Sequential([\n",
    "            layers.Conv2D(filter_count[0], filter_size[0], activation=activation, kernel_regularizer=regularizer, padding='same'),\n",
    "            layers.Conv2D(filter_count[1], filter_size[1], activation=activation, kernel_regularizer=regularizer, padding='same'),\n",
    "            layers.Conv2D(filter_count[2], filter_size[2], activation=activation, kernel_regularizer=regularizer, padding='same'),\n",
    "            layers.Conv2D(filter_count[3], filter_size[3], activation=activation, kernel_regularizer=regularizer, padding='same'),\n",
    "            layers.Conv2D(2, (1, 1), kernel_regularizer=regularizer, padding='same')\n",
    "        ])\n",
    "        \n",
    "        self.filter_count = filter_count\n",
    "        self.filter_size = filter_size\n",
    "        self.activation = activation\n",
    "        self.regularizer = regularizer\n",
    "        self.interpolation = interpolation\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filter_count\": self.filter_count,\n",
    "            \"filter_size\": self.filter_size,\n",
    "            \"activation\": self.activation,\n",
    "            \"regularizer\": self.regularizer,\n",
    "            \"interpolation\": self.interpolation,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_1 = inputs[0]\n",
    "        input_2 = inputs[1]\n",
    "        flow_1_2 = inputs[2]\n",
    "        flow_2_1 = inputs[3]\n",
    "        \n",
    "        # input_1 to input_2 flow prediction\n",
    "        input_1_warped_1 = tfa.image.dense_image_warp(input_1, flow_1_2)\n",
    "            \n",
    "        flow_change_1_2_concat = self.flow_1_2_concat([input_2, input_1_warped_1])\n",
    "        flow_change_1_2 = self.flow_prediction_1_2(flow_change_1_2_concat)\n",
    "        \n",
    "        flow_1_2_changed = self.flow_add_1_2([flow_1_2, flow_change_1_2])\n",
    "        input_1_warped_2 = tfa.image.dense_image_warp(input_1, flow_1_2_changed)\n",
    "        flow_1_2_changed_upsampled = self.flow_upsample_1_2(flow_1_2_changed)\n",
    "        \n",
    "        # input_2 to input_1 flow prediction\n",
    "        input_2_warped_1 = tfa.image.dense_image_warp(input_2, flow_2_1)\n",
    "        \n",
    "        flow_change_2_1_concat = self.flow_2_1_concat([input_1, input_2_warped_1])\n",
    "        flow_change_2_1 = self.flow_prediction_2_1(flow_change_2_1_concat)\n",
    "\n",
    "        flow_2_1_changed = self.flow_add_2_1([flow_2_1, flow_change_2_1])\n",
    "        input_2_warped_2 = tfa.image.dense_image_warp(input_2, flow_2_1_changed)\n",
    "        flow_2_1_changed_upsampled = self.flow_upsample_2_1(flow_2_1_changed)\n",
    "        \n",
    "        return input_1_warped_2, input_2_warped_2, flow_1_2_changed_upsampled, flow_2_1_changed_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a685907",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_count=[16, 16, 16]\n",
    "filter_size=(3, 3)\n",
    "flow_filter_count=[16, 24, 24, 8] \n",
    "flow_filter_size=[(3, 3), (3, 3), (1, 1), (1, 1)]\n",
    "interpolation='bilinear'\n",
    "activation= 'relu'\n",
    "regularizer=None\n",
    "\n",
    "# ------------- shared layers\n",
    "cnn_1st_level_1 = layers.Conv2D(filter_count[0], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_1_1\")\n",
    "cnn_1st_level_2 = layers.Conv2D(filter_count[0], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_1_2\")\n",
    "cnn_1st_level_3 = layers.Conv2D(filter_count[0], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_1_3\")\n",
    "cnn_1st_level_4 = layers.Conv2D(filter_count[0], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_1_4\")\n",
    "\n",
    "cnn_2nd_level_1 = layers.Conv2D(filter_count[1], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_2_1\")\n",
    "cnn_2nd_level_2 = layers.Conv2D(filter_count[1], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_2_2\")\n",
    "cnn_2nd_level_3 = layers.Conv2D(filter_count[1], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_2_3\")\n",
    "\n",
    "cnn_3rd_level_1 = layers.Conv2D(filter_count[2], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_3_1\")\n",
    "cnn_3rd_level_2 = layers.Conv2D(filter_count[2], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same', name=\"cnn_fe_3_2\")\n",
    "\n",
    "# ------------- feature extraction left side\n",
    "input_1_left = layers.Input(shape=(height, width, 3), name=\"input_left\")\n",
    "input_2_left = layers.AveragePooling2D((2, 2), name=\"avg_input_left_1/2\")(input_1_left)\n",
    "input_3_left = layers.AveragePooling2D((2, 2), name=\"avg_input_left_1/4\")(input_2_left)\n",
    "input_4_left = layers.AveragePooling2D((2, 2), name=\"avg_input_left_1/8\")(input_3_left)\n",
    "\n",
    "# feature extraction for layer 1\n",
    "input_1_column_1_row_1_left = cnn_1st_level_1(input_1_left)\n",
    "input_2_column_1_row_2_left = cnn_1st_level_2(input_2_left)\n",
    "input_3_column_1_row_3_left = cnn_1st_level_3(input_3_left)\n",
    "input_4_column_1_row_4_left = cnn_1st_level_4(input_4_left)\n",
    "\n",
    "# downsample layer 1\n",
    "input_1_column_2_row_2_left = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_left_1_1/2\")(input_1_column_1_row_1_left)\n",
    "input_2_column_2_row_3_left = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_left_1_1/4\")(input_2_column_1_row_2_left)\n",
    "input_3_column_2_row_4_left = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_left_1_1/8\")(input_3_column_1_row_3_left)\n",
    "\n",
    "# feature extraction for layer 2\n",
    "input_1_column_2_row_2_left = cnn_2nd_level_1(input_1_column_2_row_2_left)\n",
    "input_2_column_2_row_3_left = cnn_2nd_level_2(input_2_column_2_row_3_left)\n",
    "input_3_column_2_row_4_left = cnn_2nd_level_3(input_3_column_2_row_4_left)\n",
    "\n",
    "# downsample layer 2\n",
    "input_1_column_3_row_3_left = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_left_2_1/4\")(input_1_column_2_row_2_left)\n",
    "input_2_column_3_row_4_left = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_left_2_1/8\")(input_2_column_2_row_3_left)\n",
    "\n",
    "# feature extraction for layer 3\n",
    "input_1_column_3_row_3_left = cnn_3rd_level_1(input_1_column_3_row_3_left)\n",
    "input_2_column_3_row_4_left = cnn_3rd_level_2(input_2_column_3_row_4_left)\n",
    "\n",
    "# concatenate\n",
    "concat_2nd_left = layers.Concatenate(name=\"con_left_2\")([input_2_column_1_row_2_left, input_1_column_2_row_2_left])\n",
    "concat_3rd_left = layers.Concatenate(name=\"con_left_3\")([input_3_column_1_row_3_left, input_2_column_2_row_3_left, input_1_column_3_row_3_left])\n",
    "concat_4th_left = layers.Concatenate(name=\"con_left_4\")([input_4_column_1_row_4_left, input_3_column_2_row_4_left, input_2_column_3_row_4_left])\n",
    "\n",
    "# output from feature extraction left side: input_1_column_1_row_1_left, concat_2nd_left, concat_3rd_left, concat_4th_left\n",
    "\n",
    "# ------------- feature extraction left side\n",
    "input_1_right = layers.Input(shape=(height, width, 3), name=\"input_right\")\n",
    "input_2_right = layers.AveragePooling2D((2, 2), name=\"avg_input_right_1/2\")(input_1_right)\n",
    "input_3_right = layers.AveragePooling2D((2, 2), name=\"avg_input_right_1/4\")(input_2_right)\n",
    "input_4_right = layers.AveragePooling2D((2, 2), name=\"avg_input_right_1/8\")(input_3_right)\n",
    "\n",
    "# feature extraction for layer 1\n",
    "input_1_column_1_row_1_right = cnn_1st_level_1(input_1_right)\n",
    "input_2_column_1_row_2_right = cnn_1st_level_2(input_2_right)\n",
    "input_3_column_1_row_3_right = cnn_1st_level_3(input_3_right)\n",
    "input_4_column_1_row_4_right = cnn_1st_level_4(input_4_right)\n",
    "\n",
    "# downsample layer 1\n",
    "input_1_column_2_row_2_right = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_right_1_1/2\")(input_1_column_1_row_1_right)\n",
    "input_2_column_2_row_3_right = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_right_1_1/4\")(input_2_column_1_row_2_right)\n",
    "input_3_column_2_row_4_right = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_right_1_1/8\")(input_3_column_1_row_3_right)\n",
    "\n",
    "# feature extraction for layer 2\n",
    "input_1_column_2_row_2_right = cnn_2nd_level_1(input_1_column_2_row_2_right)\n",
    "input_2_column_2_row_3_right = cnn_2nd_level_2(input_2_column_2_row_3_right)\n",
    "input_3_column_2_row_4_right = cnn_2nd_level_3(input_3_column_2_row_4_right)\n",
    "\n",
    "# downsample layer 2\n",
    "input_1_column_3_row_3_right = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_right_2_1/4\")(input_1_column_2_row_2_right)\n",
    "input_2_column_3_row_4_right = layers.AveragePooling2D((2, 2), name=\"avg_cnn_fe_right_2_1/8\")(input_2_column_2_row_3_right)\n",
    "\n",
    "# feature extraction for layer 3\n",
    "input_1_column_3_row_3_right = cnn_3rd_level_1(input_1_column_3_row_3_right)\n",
    "input_2_column_3_row_4_right = cnn_3rd_level_2(input_2_column_3_row_4_right)\n",
    "\n",
    "# concatenate\n",
    "concat_2nd_right = layers.Concatenate(name=\"con_right_2\")([input_2_column_1_row_2_right, input_1_column_2_row_2_right])\n",
    "concat_3rd_right = layers.Concatenate(name=\"con_right_3\")([input_3_column_1_row_3_right, input_2_column_2_row_3_right, input_1_column_3_row_3_right])\n",
    "concat_4th_right = layers.Concatenate(name=\"con_right_4\")([input_4_column_1_row_4_right, input_3_column_2_row_4_right, input_2_column_3_row_4_right])\n",
    "\n",
    "# output from feature extraction left side: input_1_column_1_row_1_right, concat_2nd_right, concat_3rd_right, concat_4th_right\n",
    "\n",
    "# ------------- warping features at each level     \n",
    "# for flow estimation\n",
    "bidirectional_flow_estimation_1 = BidirectionalFlowEstimation(\n",
    "    filter_count=flow_filter_count, \n",
    "    filter_size=flow_filter_size, \n",
    "    activation=activation, \n",
    "    regularizer=regularizer, \n",
    "    interpolation=interpolation,\n",
    "    name=\"bi_blow_1st\"\n",
    ")\n",
    "bidirectional_flow_estimation_2 = BidirectionalFlowEstimation(\n",
    "    filter_count=flow_filter_count, \n",
    "    filter_size=flow_filter_size, \n",
    "    activation=activation, \n",
    "    regularizer=regularizer, \n",
    "    interpolation=interpolation,\n",
    "    name=\"bi_blow_2nd\"\n",
    ")\n",
    "bidirectional_flow_estimation_3 = BidirectionalFlowEstimation(\n",
    "    filter_count=flow_filter_count, \n",
    "    filter_size=flow_filter_size, \n",
    "    activation=activation, \n",
    "    regularizer=regularizer, \n",
    "    interpolation=interpolation,\n",
    "    name=\"bi_blow_above_3rd\"\n",
    ")\n",
    "\n",
    "# create empty flow for the coarest level\n",
    "empty_flow_1 = tf.zeros(shape=(batch_size, height//8, width//8, 2))\n",
    "empty_flow_2 = tf.zeros(shape=(batch_size, height//8, width//8, 2))\n",
    "\n",
    "# calculate the flow for each level using the input of current level and the upsampled flow from the level + 1\n",
    "bfe_4_i1, bfe_4_i2, bfe_4_f_1_2, bfe_4_f_2_1 = bidirectional_flow_estimation_3([concat_4th_left, concat_4th_right, empty_flow_1, empty_flow_2])\n",
    "bfe_3_i1, bfe_3_i2, bfe_3_f_1_2, bfe_3_f_2_1 = bidirectional_flow_estimation_3([concat_3rd_left, concat_3rd_right, bfe_4_f_1_2, bfe_4_f_2_1])\n",
    "bfe_2_i1, bfe_2_i2, bfe_2_f_1_2, bfe_2_f_2_1 = bidirectional_flow_estimation_2([concat_2nd_left, concat_2nd_right, bfe_3_f_1_2, bfe_3_f_2_1])\n",
    "bfe_1_i1, bfe_1_i2, _, _ = bidirectional_flow_estimation_1([input_1_column_1_row_1_left, input_1_column_1_row_1_right, bfe_2_f_1_2, bfe_2_f_2_1])\n",
    "\n",
    "# returned by warping: (bfe_1_i1, bfe_2_i1, bfe_3_i1, bfe_4_i1), (bfe_1_i2, bfe_2_i2, bfe_3_i2, bfe_4_i2)\n",
    "\n",
    "# ------------- warped features fusion   \n",
    "        \n",
    "# merge 4th level\n",
    "added_4th_level = layers.Add()([bfe_4_i1, bfe_4_i2])\n",
    "cnn_4th_1 = layers.Conv2D(filter_count[0] + filter_count[1] + filter_count[2], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same')(added_4th_level)\n",
    "cnn_4th_2 = layers.Conv2D(filter_count[0] + filter_count[1] + filter_count[2], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same')(cnn_4th_1)\n",
    "up_4th = layers.UpSampling2D((2, 2), interpolation=interpolation)(cnn_4th_2)\n",
    "\n",
    "# merge 3rd level\n",
    "added_3rd_level = layers.Add()([bfe_3_i1, bfe_3_i2, up_4th])\n",
    "cnn_3rd_1 = layers.Conv2D(filter_count[0] + filter_count[1], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same')(added_3rd_level)\n",
    "cnn_3rd_2 = layers.Conv2D(filter_count[0] + filter_count[1], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same')(cnn_3rd_1)\n",
    "up_3rd = layers.UpSampling2D((2, 2), interpolation=interpolation)(cnn_3rd_2)\n",
    "\n",
    "# merge 2nd level\n",
    "added_2nd_level = layers.Add()([bfe_2_i1, bfe_2_i2, up_3rd])\n",
    "cnn_2nd_1 = layers.Conv2D(filter_count[0], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same')(added_2nd_level)\n",
    "cnn_2nd_2 = layers.Conv2D(filter_count[0], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same')(cnn_2nd_1)\n",
    "up_2nd = layers.UpSampling2D((2, 2), interpolation=interpolation)(cnn_2nd_2)\n",
    "\n",
    "# merge 1st level\n",
    "added_1st_level = layers.Add()([bfe_1_i1, bfe_1_i2, up_2nd])\n",
    "x = layers.Conv2D(filter_count[0], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same')(added_1st_level)\n",
    "x = layers.Conv2D(filter_count[0], filter_size, activation=activation, kernel_regularizer=regularizer, padding='same')(x)\n",
    "\n",
    "# net output\n",
    "outputs = layers.Conv2D(3, (1, 1), activation=output_activation, padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b987d3a",
   "metadata": {},
   "source": [
    "## Create the final custom loss function & build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af07693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    ssim_ = ssim(y_true, y_pred)\n",
    "    psnr_ = psnr(y_true, y_pred)\n",
    "    l1_ = l1(y_true, y_pred)\n",
    "    l2_ = l2(y_true, y_pred)\n",
    "    return ssim_ + psnr_ + 5.0*l1_ + 10.0*l2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f73780d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_left (InputLayer)        [(None, 144, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_right (InputLayer)       [(None, 144, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " avg_input_left_1/2 (AveragePoo  (None, 72, 128, 3)  0           ['input_left[0][0]']             \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " avg_input_right_1/2 (AveragePo  (None, 72, 128, 3)  0           ['input_right[0][0]']            \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " cnn_fe_1_2 (Conv2D)            (None, 72, 128, 16)  448         ['avg_input_left_1/2[0][0]',     \n",
      "                                                                  'avg_input_right_1/2[0][0]']    \n",
      "                                                                                                  \n",
      " avg_input_left_1/4 (AveragePoo  (None, 36, 64, 3)   0           ['avg_input_left_1/2[0][0]']     \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " avg_cnn_fe_left_1_1/4 (Average  (None, 36, 64, 16)  0           ['cnn_fe_1_2[0][0]']             \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " avg_input_right_1/4 (AveragePo  (None, 36, 64, 3)   0           ['avg_input_right_1/2[0][0]']    \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " avg_cnn_fe_right_1_1/4 (Averag  (None, 36, 64, 16)  0           ['cnn_fe_1_2[1][0]']             \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " cnn_fe_1_3 (Conv2D)            (None, 36, 64, 16)   448         ['avg_input_left_1/4[0][0]',     \n",
      "                                                                  'avg_input_right_1/4[0][0]']    \n",
      "                                                                                                  \n",
      " cnn_fe_2_2 (Conv2D)            (None, 36, 64, 16)   2320        ['avg_cnn_fe_left_1_1/4[0][0]',  \n",
      "                                                                  'avg_cnn_fe_right_1_1/4[0][0]'] \n",
      "                                                                                                  \n",
      " avg_input_left_1/8 (AveragePoo  (None, 18, 32, 3)   0           ['avg_input_left_1/4[0][0]']     \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " avg_cnn_fe_left_1_1/8 (Average  (None, 18, 32, 16)  0           ['cnn_fe_1_3[0][0]']             \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " avg_cnn_fe_left_2_1/8 (Average  (None, 18, 32, 16)  0           ['cnn_fe_2_2[0][0]']             \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " avg_input_right_1/8 (AveragePo  (None, 18, 32, 3)   0           ['avg_input_right_1/4[0][0]']    \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " avg_cnn_fe_right_1_1/8 (Averag  (None, 18, 32, 16)  0           ['cnn_fe_1_3[1][0]']             \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " avg_cnn_fe_right_2_1/8 (Averag  (None, 18, 32, 16)  0           ['cnn_fe_2_2[1][0]']             \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " cnn_fe_1_1 (Conv2D)            (None, 144, 256, 16  448         ['input_left[0][0]',             \n",
      "                                )                                 'input_right[0][0]']            \n",
      "                                                                                                  \n",
      " cnn_fe_1_4 (Conv2D)            (None, 18, 32, 16)   448         ['avg_input_left_1/8[0][0]',     \n",
      "                                                                  'avg_input_right_1/8[0][0]']    \n",
      "                                                                                                  \n",
      " cnn_fe_2_3 (Conv2D)            (None, 18, 32, 16)   2320        ['avg_cnn_fe_left_1_1/8[0][0]',  \n",
      "                                                                  'avg_cnn_fe_right_1_1/8[0][0]'] \n",
      "                                                                                                  \n",
      " cnn_fe_3_2 (Conv2D)            (None, 18, 32, 16)   2320        ['avg_cnn_fe_left_2_1/8[0][0]',  \n",
      "                                                                  'avg_cnn_fe_right_2_1/8[0][0]'] \n",
      "                                                                                                  \n",
      " avg_cnn_fe_left_1_1/2 (Average  (None, 72, 128, 16)  0          ['cnn_fe_1_1[0][0]']             \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " avg_cnn_fe_right_1_1/2 (Averag  (None, 72, 128, 16)  0          ['cnn_fe_1_1[1][0]']             \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " con_left_4 (Concatenate)       (None, 18, 32, 48)   0           ['cnn_fe_1_4[0][0]',             \n",
      "                                                                  'cnn_fe_2_3[0][0]',             \n",
      "                                                                  'cnn_fe_3_2[0][0]']             \n",
      "                                                                                                  \n",
      " con_right_4 (Concatenate)      (None, 18, 32, 48)   0           ['cnn_fe_1_4[1][0]',             \n",
      "                                                                  'cnn_fe_2_3[1][0]',             \n",
      "                                                                  'cnn_fe_3_2[1][0]']             \n",
      "                                                                                                  \n",
      " cnn_fe_2_1 (Conv2D)            (None, 72, 128, 16)  2320        ['avg_cnn_fe_left_1_1/2[0][0]',  \n",
      "                                                                  'avg_cnn_fe_right_1_1/2[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bi_blow_above_3rd (Bidirection  multiple            36276       ['con_left_4[0][0]',             \n",
      " alFlowEstimation)                                                'con_right_4[0][0]',            \n",
      "                                                                  'con_left_3[0][0]',             \n",
      "                                                                  'con_right_3[0][0]',            \n",
      "                                                                  'bi_blow_above_3rd[0][2]',      \n",
      "                                                                  'bi_blow_above_3rd[0][3]']      \n",
      "                                                                                                  \n",
      " avg_cnn_fe_left_2_1/4 (Average  (None, 36, 64, 16)  0           ['cnn_fe_2_1[0][0]']             \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " avg_cnn_fe_right_2_1/4 (Averag  (None, 36, 64, 16)  0           ['cnn_fe_2_1[1][0]']             \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (5, 18, 32, 48)      0           ['bi_blow_above_3rd[0][0]',      \n",
      "                                                                  'bi_blow_above_3rd[0][1]']      \n",
      "                                                                                                  \n",
      " cnn_fe_3_1 (Conv2D)            (None, 36, 64, 16)   2320        ['avg_cnn_fe_left_2_1/4[0][0]',  \n",
      "                                                                  'avg_cnn_fe_right_2_1/4[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (5, 18, 32, 48)      20784       ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " con_left_3 (Concatenate)       (None, 36, 64, 48)   0           ['cnn_fe_1_3[0][0]',             \n",
      "                                                                  'cnn_fe_2_2[0][0]',             \n",
      "                                                                  'cnn_fe_3_1[0][0]']             \n",
      "                                                                                                  \n",
      " con_right_3 (Concatenate)      (None, 36, 64, 48)   0           ['cnn_fe_1_3[1][0]',             \n",
      "                                                                  'cnn_fe_2_2[1][0]',             \n",
      "                                                                  'cnn_fe_3_1[1][0]']             \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (5, 18, 32, 48)      20784       ['conv2d_69[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampling2D  (5, 36, 64, 48)     0           ['conv2d_70[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (5, 36, 64, 48)      0           ['bi_blow_above_3rd[1][0]',      \n",
      "                                                                  'bi_blow_above_3rd[1][1]',      \n",
      "                                                                  'up_sampling2d_15[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (5, 36, 64, 32)      13856       ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " con_left_2 (Concatenate)       (None, 72, 128, 32)  0           ['cnn_fe_1_2[0][0]',             \n",
      "                                                                  'cnn_fe_2_1[0][0]']             \n",
      "                                                                                                  \n",
      " con_right_2 (Concatenate)      (None, 72, 128, 32)  0           ['cnn_fe_1_2[1][0]',             \n",
      "                                                                  'cnn_fe_2_1[1][0]']             \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (5, 36, 64, 32)      9248        ['conv2d_71[0][0]']              \n",
      "                                                                                                  \n",
      " bi_blow_2nd (BidirectionalFlow  ((5, 72, 128, 32),  27060       ['con_left_2[0][0]',             \n",
      " Estimation)                     (5, 72, 128, 32),                'con_right_2[0][0]',            \n",
      "                                 (5, 144, 256, 2),                'bi_blow_above_3rd[1][2]',      \n",
      "                                 (5, 144, 256, 2))                'bi_blow_above_3rd[1][3]']      \n",
      "                                                                                                  \n",
      " up_sampling2d_16 (UpSampling2D  (5, 72, 128, 32)    0           ['conv2d_72[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (5, 72, 128, 32)     0           ['bi_blow_2nd[0][0]',            \n",
      "                                                                  'bi_blow_2nd[0][1]',            \n",
      "                                                                  'up_sampling2d_16[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (5, 72, 128, 16)     4624        ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (5, 72, 128, 16)     2320        ['conv2d_73[0][0]']              \n",
      "                                                                                                  \n",
      " bi_blow_1st (BidirectionalFlow  ((5, 144, 256, 16),  17844      ['cnn_fe_1_1[0][0]',             \n",
      " Estimation)                     (5, 144, 256, 16),               'cnn_fe_1_1[1][0]',             \n",
      "                                 (5, 288, 512, 2),                'bi_blow_2nd[0][2]',            \n",
      "                                 (5, 288, 512, 2))                'bi_blow_2nd[0][3]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_17 (UpSampling2D  (5, 144, 256, 16)   0           ['conv2d_74[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (5, 144, 256, 16)    0           ['bi_blow_1st[0][0]',            \n",
      "                                                                  'bi_blow_1st[0][1]',            \n",
      "                                                                  'up_sampling2d_17[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (5, 144, 256, 16)    2320        ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (5, 144, 256, 16)    2320        ['conv2d_75[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (5, 144, 256, 3)     51          ['conv2d_76[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 170,879\n",
      "Trainable params: 170,879\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create and compile the model\n",
    "model = keras.Model(inputs=[input_1_left, input_1_right], outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    loss = loss,\n",
    "    optimizer = optimizers.Nadam(0.0001, clipnorm=0.5),\n",
    "    metrics = [l1, l2, psnr, ssim]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70e32a",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e680e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 458/3800 [==>...........................] - ETA: 12:57 - loss: 1.2403 - l1: 0.0636 - l2: 0.0144 - psnr: 0.4475 - ssim: 0.3312"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data = valid_generator,\n",
    "    steps_per_epoch = int(data_train_size) // batch_size,\n",
    "    validation_steps = int(data_valid_size) // batch_size,\n",
    "    callbacks = [\n",
    "        callbacks.ModelCheckpoint(\n",
    "            os.path.join(model_base_path, model_name+'_'+'{loss:.4f}_{epoch:02d}_'+str(int(time.time()))+'.h5'),\n",
    "            monitor = 'loss',\n",
    "            mode = 'min',\n",
    "            save_best_only = True,\n",
    "            save_weights_only = False,\n",
    "            save_freq = 200,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223c125",
   "metadata": {},
   "source": [
    "## Evaluate the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f764e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_0_1(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def norm(data):\n",
    "    return (data - np.mean(data)) / np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854788cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, normalize_method=None, metrics_restrictions=None):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(25,10))\n",
    "    \n",
    "    metrics = list(history.keys())\n",
    "    metrics = [metric for metric in metrics if \"val\" not in metric]\n",
    "    if metrics_restrictions is not None:\n",
    "        metrics = [metric for metric in metrics if metric in metrics_restrictions]\n",
    "    \n",
    "    data = [(index, history[metric], history['val_'+metric], metric) for index, metric in enumerate(metrics)]\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "    epochs = range(1, len(data[0][1]) + 1)\n",
    "    \n",
    "    for index, value, val_value, metric in data:\n",
    "        if normalize_method is not None:\n",
    "            buffer = value.copy()\n",
    "            buffer.extend(val_value)\n",
    "            buffer = normalize_method(buffer)\n",
    "            value = buffer[0:len(epochs)]\n",
    "            val_value = buffer[len(epochs)::]\n",
    "        \n",
    "        plt.plot(epochs, value, colors[index], label=f\"Training {metric}\")\n",
    "        plt.plot(epochs, val_value, colors[index]+'--', label=f\"Validation {metric}\")\n",
    "        \n",
    "    plt.xticks(epochs, size=17)    \n",
    "    plt.yticks(size=17)\n",
    "    plt.title(f\"Comparison of Training and Validation metrics\", size=20)\n",
    "    plt.xlabel('Epochs', size=17)\n",
    "    plt.ylabel(\"Metric values\", size=17)\n",
    "    plt.legend(loc='upper right', fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf081a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, generator, verbose=0):\n",
    "    result_dict = {}\n",
    "    result = model.evaluate(generator, verbose=verbose)\n",
    "    for index, metric in enumerate(model.metrics):\n",
    "        result_dict[metric.name] = result[index]\n",
    "        print(f'{metric.name.zfill(13).replace(\"0\", \" \")}: {np.round(result[index], 4)}')\n",
    "        \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, normalize_method=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d603be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, normalize_method=norm_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fff560",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, normalize_method=None, metrics_restrictions=['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate(model, test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75696615",
   "metadata": {},
   "source": [
    "## Visualize generated frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(vis_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(generator, predictions, batch, index):\n",
    "    # verify arguments\n",
    "    batch_size = generator.batch_size\n",
    "    assert generator.shuffle == False\n",
    "    assert batch >= 0 and batch < len(generator)\n",
    "    assert index >= 0 and index < batch_size\n",
    "    \n",
    "    # get neighbours frames\n",
    "    neighbours, true = generator[batch]\n",
    "    neighbours = np.array(neighbours)\n",
    "    neighbours = neighbours[:, index, :, :, :]\n",
    "\n",
    "    # get true and predicted frames\n",
    "    true = np.array(true)[index]\n",
    "    predicted = predictions[batch_size*batch + index]\n",
    "    \n",
    "    # mark true edges on predicted frame\n",
    "    true_edges = cv2.cvtColor(true, cv2.COLOR_RGB2GRAY)\n",
    "    true_edges = cv2.GaussianBlur(true_edges, (3, 3), 1)\n",
    "    true_edges = cv2.medianBlur(true_edges, 3)\n",
    "    true_edges = cv2.Canny((true_edges*255).astype('uint8'), 50, 100)\n",
    "    predicted_marked = predicted.copy()\n",
    "    predicted_marked[true_edges != 0] = (1, 1, 1)\n",
    "\n",
    "    # plot images\n",
    "    f, ax = plt.subplots(3, 2)\n",
    "    f.set_size_inches(20, 20)\n",
    "\n",
    "    ax[0][0].set_title(\"First frame\")\n",
    "    ax[0][0].set_xticks([])\n",
    "    ax[0][0].set_yticks([])\n",
    "    ax[0][0].imshow(neighbours[0])\n",
    "    \n",
    "    ax[1][0].set_title(\"Predicted frame\")\n",
    "    ax[1][0].set_xticks([])\n",
    "    ax[1][0].set_yticks([])\n",
    "    ax[1][0].imshow(predicted)\n",
    "    \n",
    "    ax[2][0].set_title(\"Second frame\")\n",
    "    ax[2][0].set_xticks([])\n",
    "    ax[2][0].set_yticks([])\n",
    "    ax[2][0].imshow(neighbours[1])\n",
    "    \n",
    "    ax[0][1].set_title(\"Predicted and Ground-truth difference\")\n",
    "    ax[0][1].set_xticks([])\n",
    "    ax[0][1].set_yticks([])\n",
    "    ax[0][1].imshow(cv2.absdiff(predicted, true))\n",
    "    \n",
    "    ax[1][1].set_title(\"Ground-truth frame\")\n",
    "    ax[1][1].set_xticks([])\n",
    "    ax[1][1].set_yticks([])\n",
    "    ax[1][1].imshow(true)\n",
    "    \n",
    "    ax[2][1].set_title(\"Edge shift\")\n",
    "    ax[2][1].set_xticks([])\n",
    "    ax[2][1].set_yticks([])\n",
    "    ax[2][1].imshow(predicted_marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(vis_generator, predictions, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(vis_generator, predictions, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de64e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(vis_generator, predictions, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372924b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(vis_generator, predictions, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107dcd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(vis_generator, predictions, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20fde31",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(vis_generator, predictions, 12, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321ef17",
   "metadata": {},
   "source": [
    "## Save or load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0edb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_creation_time = int(time.time())\n",
    "model.save(os.path.join(model_base_path, f'{model_name}.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b42ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current best model\n",
    "model_best = keras.models.load_model(\n",
    "    os.path.join(model_base_path, 'frame_booster_0.5210_02_1683730177.h5'),\n",
    "    custom_objects = {\n",
    "        \"BidirectionalFlowEstimation\": BidirectionalFlowEstimation,\n",
    "        \"output_activation\": output_activation,\n",
    "        'loss': loss,\n",
    "        'l1': l1,\n",
    "        \"ssim\": ssim,\n",
    "        \"psnr\": psnr,\n",
    "        \"l2\": l2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eac68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15_2 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
